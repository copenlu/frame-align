{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_df = pd.read_csv(\"../data_pixtral_llava/val_set_full.csv\", index_col=[0])\n",
    "# human_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mini_multiple_frames_confidence_frames-list</th>\n",
       "      <th>mini_multiple_frames_confidence_reason</th>\n",
       "      <th>mini_multiple_frames_confidence_confidence</th>\n",
       "      <th>normal_multiple_frames_confidence_frames-list</th>\n",
       "      <th>normal_multiple_frames_confidence_reason</th>\n",
       "      <th>normal_multiple_frames_confidence_confidence</th>\n",
       "      <th>mini_multiple_frames_frames-list</th>\n",
       "      <th>mini_multiple_frames_reason</th>\n",
       "      <th>normal_multiple_frames_frame-list</th>\n",
       "      <th>normal_multiple_frames_reason</th>\n",
       "      <th>image_url</th>\n",
       "      <th>uuid</th>\n",
       "      <th>normal_multiple_frames_frame-justification</th>\n",
       "      <th>normal_multiple_frames_frame-name-list</th>\n",
       "      <th>normal_multiple_frames_frames-list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>[None]</td>\n",
       "      <td>The image only shows the logo of a restaurant ...</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>[None]</td>\n",
       "      <td>The image only shows the logo of a restaurant ...</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>[None]</td>\n",
       "      <td>The image only shows the logo of a restaurant ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>The image only shows the logo of a restaurant ...</td>\n",
       "      <td>data_pixtral_llava/images20c18bc5-3207-45a6-84...</td>\n",
       "      <td>20c18bc5-3207-45a6-8408-53867d1a1dfb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[Quality of life]</td>\n",
       "      <td>The image depicts individuals who appear to be...</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>[Quality of life]</td>\n",
       "      <td>The image shows individuals living in tents on...</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>[Quality of life, Public opinion]</td>\n",
       "      <td>The image depicts individuals living in tents ...</td>\n",
       "      <td>[Quality of life, None]</td>\n",
       "      <td>The image depicts individuals in a homeless en...</td>\n",
       "      <td>data_pixtral_llava/imagesd92024bc-81b6-4b8f-a4...</td>\n",
       "      <td>d92024bc-81b6-4b8f-a4d1-8824b9abc276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mini_multiple_frames_confidence_frames-list  \\\n",
       "147                                      [None]   \n",
       "44                            [Quality of life]   \n",
       "\n",
       "                mini_multiple_frames_confidence_reason  \\\n",
       "147  The image only shows the logo of a restaurant ...   \n",
       "44   The image depicts individuals who appear to be...   \n",
       "\n",
       "    mini_multiple_frames_confidence_confidence  \\\n",
       "147                            high-confidence   \n",
       "44                             high-confidence   \n",
       "\n",
       "    normal_multiple_frames_confidence_frames-list  \\\n",
       "147                                        [None]   \n",
       "44                              [Quality of life]   \n",
       "\n",
       "              normal_multiple_frames_confidence_reason  \\\n",
       "147  The image only shows the logo of a restaurant ...   \n",
       "44   The image shows individuals living in tents on...   \n",
       "\n",
       "    normal_multiple_frames_confidence_confidence  \\\n",
       "147                              high-confidence   \n",
       "44                               high-confidence   \n",
       "\n",
       "      mini_multiple_frames_frames-list  \\\n",
       "147                             [None]   \n",
       "44   [Quality of life, Public opinion]   \n",
       "\n",
       "                           mini_multiple_frames_reason  \\\n",
       "147  The image only shows the logo of a restaurant ...   \n",
       "44   The image depicts individuals living in tents ...   \n",
       "\n",
       "    normal_multiple_frames_frame-list  \\\n",
       "147                            [None]   \n",
       "44            [Quality of life, None]   \n",
       "\n",
       "                         normal_multiple_frames_reason  \\\n",
       "147  The image only shows the logo of a restaurant ...   \n",
       "44   The image depicts individuals in a homeless en...   \n",
       "\n",
       "                                             image_url  \\\n",
       "147  data_pixtral_llava/images20c18bc5-3207-45a6-84...   \n",
       "44   data_pixtral_llava/imagesd92024bc-81b6-4b8f-a4...   \n",
       "\n",
       "                                     uuid  \\\n",
       "147  20c18bc5-3207-45a6-8408-53867d1a1dfb   \n",
       "44   d92024bc-81b6-4b8f-a4d1-8824b9abc276   \n",
       "\n",
       "    normal_multiple_frames_frame-justification  \\\n",
       "147                                        NaN   \n",
       "44                                         NaN   \n",
       "\n",
       "    normal_multiple_frames_frame-name-list normal_multiple_frames_frames-list  \n",
       "147                                    NaN                                NaN  \n",
       "44                                     NaN                                NaN  "
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_df = pd.read_json(\"../data_pixtral_llava/output/multipleframes_val_set_full_pixtral_anno.jsonl\", lines=True, orient=\"records\")\n",
    "anno_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img_urls, labels, preds):\n",
    "    assert len(img_urls) == 4\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20,5))\n",
    "    for i, (url, label, pred) in enumerate(zip(img_urls, labels, preds)):\n",
    "        image = plt.imread(\"../\"+url)\n",
    "        ax[i].imshow(image)\n",
    "        ax[i].set_title(f\"Label: {label}\\nPred: {pred}\")\n",
    "        ax[i].axis(\"off\")\n",
    "\n",
    "def plot_image_title(img_url, explanation, title):\n",
    "    image = plt.imread(\"../\"+img_url)\n",
    "    plt.imshow(image)\n",
    "    plt.figtext(0.5, 0.01, explanation, wrap=True, horizontalalignment='center', fontsize=7)\n",
    "    plt.title(f\"Article Title: {title}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df = pd.read_csv(\"../data_pixtral_llava/val_set_full.csv\", index_col=[0])\n",
    "anno_df = pd.read_json(\"../data_pixtral_llava/output/multipleframes_val_set_full_pixtral_anno.jsonl\", lines=True, orient=\"records\")\n",
    "anno_df.set_index(\"uuid\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anno_df), len(human_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mini_multiple_frames_confidence_frames-list</th>\n",
       "      <th>mini_multiple_frames_confidence_reason</th>\n",
       "      <th>mini_multiple_frames_confidence_confidence</th>\n",
       "      <th>normal_multiple_frames_confidence_frames-list</th>\n",
       "      <th>normal_multiple_frames_confidence_reason</th>\n",
       "      <th>normal_multiple_frames_confidence_confidence</th>\n",
       "      <th>mini_multiple_frames_frames-list</th>\n",
       "      <th>mini_multiple_frames_reason</th>\n",
       "      <th>normal_multiple_frames_frame-list</th>\n",
       "      <th>normal_multiple_frames_reason</th>\n",
       "      <th>image_url</th>\n",
       "      <th>normal_multiple_frames_frame-justification</th>\n",
       "      <th>normal_multiple_frames_frame-name-list</th>\n",
       "      <th>normal_multiple_frames_frames-list</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d10e0afd-af7b-42d2-a7d9-de14e60a1668</th>\n",
       "      <td>[None]</td>\n",
       "      <td>The image shows a group of people, including c...</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>[None]</td>\n",
       "      <td>The image shows a group of people, including c...</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>[None]</td>\n",
       "      <td>The image shows a group of people, including c...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>The image shows a group of people, including c...</td>\n",
       "      <td>data_pixtral_llava/imagesd10e0afd-af7b-42d2-a7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8eb6159-54b9-4134-b227-1a607bfbe7e2</th>\n",
       "      <td>[None]</td>\n",
       "      <td>The image shows a word puzzle game interface w...</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>[None]</td>\n",
       "      <td>The image primarily shows a word puzzle game i...</td>\n",
       "      <td>high-confidence</td>\n",
       "      <td>[None]</td>\n",
       "      <td>The image shows a word puzzle game interface w...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>The image primarily shows a screen displaying ...</td>\n",
       "      <td>data_pixtral_llava/imagesb8eb6159-54b9-4134-b2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mini_multiple_frames_confidence_frames-list  \\\n",
       "uuid                                                                               \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668                                      [None]   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2                                      [None]   \n",
       "\n",
       "                                                 mini_multiple_frames_confidence_reason  \\\n",
       "uuid                                                                                      \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668  The image shows a group of people, including c...   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2  The image shows a word puzzle game interface w...   \n",
       "\n",
       "                                     mini_multiple_frames_confidence_confidence  \\\n",
       "uuid                                                                              \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668                            high-confidence   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2                            high-confidence   \n",
       "\n",
       "                                     normal_multiple_frames_confidence_frames-list  \\\n",
       "uuid                                                                                 \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668                                        [None]   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2                                        [None]   \n",
       "\n",
       "                                               normal_multiple_frames_confidence_reason  \\\n",
       "uuid                                                                                      \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668  The image shows a group of people, including c...   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2  The image primarily shows a word puzzle game i...   \n",
       "\n",
       "                                     normal_multiple_frames_confidence_confidence  \\\n",
       "uuid                                                                                \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668                              high-confidence   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2                              high-confidence   \n",
       "\n",
       "                                     mini_multiple_frames_frames-list  \\\n",
       "uuid                                                                    \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668                           [None]   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2                           [None]   \n",
       "\n",
       "                                                            mini_multiple_frames_reason  \\\n",
       "uuid                                                                                      \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668  The image shows a group of people, including c...   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2  The image shows a word puzzle game interface w...   \n",
       "\n",
       "                                     normal_multiple_frames_frame-list  \\\n",
       "uuid                                                                     \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668                            [None]   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2                            [None]   \n",
       "\n",
       "                                                          normal_multiple_frames_reason  \\\n",
       "uuid                                                                                      \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668  The image shows a group of people, including c...   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2  The image primarily shows a screen displaying ...   \n",
       "\n",
       "                                                                              image_url  \\\n",
       "uuid                                                                                      \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668  data_pixtral_llava/imagesd10e0afd-af7b-42d2-a7...   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2  data_pixtral_llava/imagesb8eb6159-54b9-4134-b2...   \n",
       "\n",
       "                                     normal_multiple_frames_frame-justification  \\\n",
       "uuid                                                                              \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668                                        NaN   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2                                        NaN   \n",
       "\n",
       "                                     normal_multiple_frames_frame-name-list  \\\n",
       "uuid                                                                          \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668                                    NaN   \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2                                    NaN   \n",
       "\n",
       "                                     normal_multiple_frames_frames-list  \n",
       "uuid                                                                     \n",
       "d10e0afd-af7b-42d2-a7d9-de14e60a1668                                NaN  \n",
       "b8eb6159-54b9-4134-b227-1a607bfbe7e2                                NaN  "
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['mini_multiple_frames_frames-list']#, 'normal_multiple_frames_frame-list'] #normal_multiple_frames_frames-list\n",
    "for col in label_cols:\n",
    "    for i, row in anno_df[col].items():\n",
    "        if isinstance(row, list):\n",
    "            anno_df.at[i, col] = set([i.lower() for i in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_df['merged_labels'] = human_df['merged_labels'].apply(lambda x: literal_eval(x))\n",
    "human_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = human_df.join(anno_df[label_cols+['image_url']], how=\"inner\")\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_cols:\n",
    "    merged_df[col] = merged_df[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# for col in label_cols:\n",
    "#         correct = 0\n",
    "#         for i, row in merged_df.iterrows():\n",
    "#                 if row[col] in row['merged_labels']:\n",
    "#                         correct += 1\n",
    "#         accuracy = correct / len(merged_df)\n",
    "#         results[col] = accuracy\n",
    "#         print(col, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(results, index=[\"accuracy\"]).T.plot(kind=\"barh\", figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = anno_df[[\"mini_multiple_frames_frames-list\",\"mini_multiple_frames_reason\", 'image_url']]\n",
    "pred_df.columns = ['pred_labels', 'pred_reason', 'image_url']\n",
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df.columns = ['human_annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_labels</th>\n",
       "      <th>human_annotations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e78308e9-8c49-4217-9bb2-ef93a4b82b90</th>\n",
       "      <td>{security and defense, crime and punishment}</td>\n",
       "      <td>{security and defense, fairness and equality, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261799f-3a92-4805-bc56-3252dd645d89</th>\n",
       "      <td>{security and defense, none}</td>\n",
       "      <td>{security and defense}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80164efd-4678-4b00-92c6-eec6162e0cf1</th>\n",
       "      <td>{none}</td>\n",
       "      <td>{none, quality of life}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e336c7fb-895c-4d87-a384-2b1e479cdb9c</th>\n",
       "      <td>{quality of life}</td>\n",
       "      <td>{none, quality of life}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0054ad1b-896e-42cf-a3fb-c9eedea17ec4</th>\n",
       "      <td>{legality, constitutionality and jurisprudence...</td>\n",
       "      <td>{political}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            pred_labels  \\\n",
       "uuid                                                                                      \n",
       "e78308e9-8c49-4217-9bb2-ef93a4b82b90       {security and defense, crime and punishment}   \n",
       "6261799f-3a92-4805-bc56-3252dd645d89                       {security and defense, none}   \n",
       "80164efd-4678-4b00-92c6-eec6162e0cf1                                             {none}   \n",
       "e336c7fb-895c-4d87-a384-2b1e479cdb9c                                  {quality of life}   \n",
       "0054ad1b-896e-42cf-a3fb-c9eedea17ec4  {legality, constitutionality and jurisprudence...   \n",
       "\n",
       "                                                                      human_annotations  \n",
       "uuid                                                                                     \n",
       "e78308e9-8c49-4217-9bb2-ef93a4b82b90  {security and defense, fairness and equality, ...  \n",
       "6261799f-3a92-4805-bc56-3252dd645d89                             {security and defense}  \n",
       "80164efd-4678-4b00-92c6-eec6162e0cf1                            {none, quality of life}  \n",
       "e336c7fb-895c-4d87-a384-2b1e479cdb9c                            {none, quality of life}  \n",
       "0054ad1b-896e-42cf-a3fb-c9eedea17ec4                                        {political}  "
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_df = pred_df['pred_labels'].dropna()\n",
    "merged_df = pd.merge(dropped_df, human_df, left_index=True, right_index=True)\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7866666666666666\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "merged_df['intersection'] = merged_df.apply(lambda x: x['pred_labels'].intersection(x['human_annotations']), axis=1)\n",
    "merged_df['intersection_len'] = merged_df['intersection'].apply(len)\n",
    "merged_df['correct'] = merged_df['intersection_len'] > 0\n",
    "print(merged_df['correct'].sum()/len(dropped_df))\n",
    "print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing model None values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8418367346938775\n",
      "Shape of filtered_df: (196, 5)\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where the model prediction is 'None'\n",
    "filtered_df = pred_df[pred_df['pred_labels'] != {'none'}]\n",
    "\n",
    "# Perform the same calculation on the filtered DataFrame\n",
    "dropped_df_filtered = filtered_df['pred_labels'].dropna()\n",
    "merged_df_filtered = pd.merge(dropped_df_filtered, human_df, left_index=True, right_index=True)\n",
    "merged_df_filtered['intersection'] = merged_df_filtered.apply(lambda x: x['pred_labels'].intersection(x['human_annotations']), axis=1)\n",
    "merged_df_filtered['intersection_len'] = merged_df_filtered['intersection'].apply(len)\n",
    "merged_df_filtered['correct'] = merged_df_filtered['intersection_len'] > 0\n",
    "\n",
    "# Print the accuracy\n",
    "print(merged_df_filtered['correct'].sum() / len(dropped_df_filtered))\n",
    "print(f\"Shape of filtered_df: {merged_df_filtered.shape}\")\n",
    "print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove sports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_filtered.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 2)\n",
      "(181, 2)\n",
      "0.8342541436464088\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "no_sports_csv = pd.read_csv('../notebooks/sample_no_sports.csv')\n",
    "no_sports_uuids = no_sports_csv['id'].tolist()\n",
    "\n",
    "# Filter out rows where the model prediction is 'None'\n",
    "filtered_df = pred_df[pred_df['pred_labels'] != {'none'}]\n",
    "\n",
    "# Perform the same calculation on the filtered DataFrame\n",
    "dropped_df_filtered = filtered_df['pred_labels'].dropna()\n",
    "merged_df_filtered = pd.merge(dropped_df_filtered, human_df, left_index=True, right_index=True)\n",
    "print(merged_df_filtered.shape)\n",
    "\n",
    "# Filter out rows where the UUID is not in no_sports_uuids\n",
    "merged_df_filtered_no_sports = merged_df_filtered[merged_df_filtered.index.isin(no_sports_uuids)].copy()\n",
    "print(merged_df_filtered_no_sports.shape)\n",
    "\n",
    "merged_df_filtered_no_sports['intersection'] = merged_df_filtered_no_sports['pred_labels'].combine(\n",
    "    merged_df_filtered_no_sports['human_annotations'], \n",
    "    lambda x, y: x.intersection(y)\n",
    ")\n",
    "merged_df_filtered_no_sports['intersection_len'] = merged_df_filtered_no_sports['intersection'].apply(len)\n",
    "merged_df_filtered_no_sports['correct'] = merged_df_filtered_no_sports['intersection_len'] > 0\n",
    "\n",
    "# Print the accuracy\n",
    "print(merged_df_filtered_no_sports['correct'].sum() / len(merged_df_filtered_no_sports))\n",
    "print(\"------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "def image_base64(im):\n",
    "    if isinstance(im, str):\n",
    "        im = Image.open(im)\n",
    "    with BytesIO() as buffer:\n",
    "        im.save(buffer, 'jpeg')\n",
    "        return base64.b64encode(buffer.getvalue()).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = pred_df.merge(human_df, left_index=True, right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df['image_url'] = merged_df['image_url'].str.replace('data_pixtral_llava/images', '')\n",
    "\n",
    "# img_paths = merged_df['image_url'].apply(lambda x: \"../data_pixtral_llava/images/\" + x.split('/')[-1]).tolist()\n",
    "# # print(img_paths)\n",
    "# imgStrs = [image_base64(img_path) for img_path in img_paths]\n",
    "\n",
    "# merged_df['Image'] = [f'<img width=400 src=\"data:image/png;base64,{imgStr}\">' for imgStr in imgStrs]\n",
    "# merged_df.drop(columns=['image_url'], inplace=True)\n",
    "# merged_df.to_html(\"../data_pixtral_llava/pixtral_anno_multi_frames_val_set.html\", escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_incorrect = merged_df[merged_df[\"intersection_len\"] == 0].sample(4)\n",
    "# plot_image(sample_incorrect['image_url'], sample_incorrect['merged_labels'], sample_incorrect['normal_multiple_frames_frame-list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_image(sample_incorrect['image_url'], sample_incorrect['merged_labels'], sample_incorrect['frame-name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frame-align",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
